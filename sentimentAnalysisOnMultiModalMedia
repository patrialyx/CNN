# -*- coding: utf-8 -*-
"""bitresnet_layerz_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jgPd8XxL29Kh7gH0xFs8ZS1LCaWak1Ag
"""

####run the first legit test on overallsentiment, memotion data set

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
import tensorflow_hub as hub
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input
from keras.preprocessing.image import ImageDataGenerator
from keras import models, Model, layers, optimizers, callbacks, applications
from keras.optimizers import RMSprop, SGD
#from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, CSVLogger, LearningRateScheduler, ProgbarLogger, ReduceLROnPlateau
import pandas as pd
import csv
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from PIL import ImageFile
from keras.applications import Xception
from sklearn.utils.class_weight import compute_class_weight

####################   CHANGE    ########################

print('creating directories')
curr_dir = "/content/drive/My Drive"
train_dir = os.path.join(curr_dir,"the whole memotion dir/train/Overall_sentiment")
validation_dir = os.path.join(curr_dir,"the whole memotion dir/eval/Overall_sentiment")
print('train_dir', train_dir)
print('validation_dir', validation_dir)

BATCH_SIZE = 32
TARGET_SIZE = (224, 224)
NUM_CLASSES = 5
FILENAME = 'BiT-M_layerz_result_1'
EPOCHS = 300
saved_area = os.path.join(curr_dir, "saved_models_2/BiT-M_layerz/result_1")
CHKPT_FILEPATH = os.path.join(saved_area,'cp-{epoch:03d}-{val_accuracy:.5f}.h5')

MODULE_HANDLE ="https://tfhub.dev/google/bit/m-r50x1/ilsvrc2012_classification/1"
CONV_BASE = hub.KerasLayer(MODULE_HANDLE, trainable=True)
OPTIMIZER = keras.optimizers.SGD(learning_rate=0.003, momentum=0.9)
A_PATIENCE = 20
B_PATIENCE = 10

from google.colab import drive
drive.mount('/content/drive')

#####################   BUILD MODEL  ###############################

model = tf.keras.Sequential([
    # Explicitly define the input shape so the model can be properly
    # loaded by the TFLiteConverter
    tf.keras.layers.InputLayer(input_shape=TARGET_SIZE + (3,)),
    hub.KerasLayer(MODULE_HANDLE, trainable=False),
    tf.keras.layers.Dense(128, activation = 'relu'),
    tf.keras.layers.Dense(NUM_CLASSES, activation ="softmax")
])

# from tensorflow.keras.models import load_model
# model = load_model('/content/drive/My Drive/saved_models_2/BiT-M/result_1/cp-002-0.28009.h5', custom_objects={'KerasLayer':hub.KerasLayer})

model.summary()

######################   COMPILE MODEL   ##########################
model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),
              optimizer=OPTIMIZER,
              metrics=['accuracy'])

#######################   GENERATE IMAGES   #############################
              
 
datagen = ImageDataGenerator()
print('train generator')
train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=TARGET_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical')

print('validation generator')
validation_generator = datagen.flow_from_directory(
    validation_dir,
    target_size=TARGET_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical')

########################   CREATE CHECKPOINT/RUN MODEL   #########################################

print('checkpointing')
ImageFile.LOAD_TRUNCATED_IMAGES = True
sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))

my_callbacks = [tf.keras.callbacks.EarlyStopping(
                  monitor='val_accuracy', 
                  patience=A_PATIENCE, 
                  verbose = 1, 
                  restore_best_weights = True
                  ), 
                tf.keras.callbacks.ModelCheckpoint(
                  filepath=CHKPT_FILEPATH, 
                  monitor='val_accuracy', 
                  verbose=1, 
                  save_best_only=True, 
                  save_weights_only=False
                  )
                # tf.keras.callbacks.ReduceLROnPlateau(
                #   monitor='val_loss', 
                #   factor=0.05, 
                #   patience=B_PATIENCE, 
                #   verbose=1
                #   )
                ]
                
class_weight_list = compute_class_weight('balanced', np.unique(validation_generator.classes), validation_generator.classes)
class_weight = dict(zip(np.unique(validation_generator.classes), class_weight_list))

print('history')
history = model.fit(
    train_generator,
    callbacks = my_callbacks,
    class_weight = class_weight,
    epochs=EPOCHS,
    validation_data=validation_generator,
    verbose=2)

######################   OTHER EVALUATIONS ON THE TEST SET  ##########################################


test_dir = os.path.join(curr_dir, 'the whole memotion dir/memotion_test_set/Overall_sentiment')
print('test_dir:', test_dir)

datagen = ImageDataGenerator()
print('test generator')
test_generator = datagen.flow_from_directory(
    test_dir,
    target_size=TARGET_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical')

predictions = model.predict(
                test_generator,
                verbose = 1
              )
              
print('test_preds')      
test_preds = np.argmax(predictions, axis=-1)
print(test_preds)

print('test_trues')
test_trues = test_generator.classes
print(test_trues)

print('confusion matrix')
cm = confusion_matrix(test_trues, test_preds)
df3 = pd.DataFrame(cm)
df3.to_csv(os.path.join(saved_area, '{}.csv'.format(FILENAME)), mode='a')
print(cm)

###########################   IMPORTANT METRICS    ##########################################

print('classification report')
report = pd.DataFrame(classification_report(test_trues, test_preds, output_dict=True)).transpose()
report.to_csv(os.path.join(saved_area, '{}.csv'.format(FILENAME)), mode='a')

loss, acc = model.evaluate(test_generator, verbose=2)
print("Accuracy: {:5.5f}%".format(100*acc))

print('append to csv file')
with open(os.path.join(saved_area,'{}.csv'.format(FILENAME)),'a') as fd:
    fd.write('loss: {}'.format(loss))
    fd.write('\n')
    fd.write('acc: {}'.format(acc))
    fd.close()
